# Google Colab + VS Code Guide for HITL Experiment

## üéØ Purpose

Run the complete HITL proof-of-concept experiment on Google Colab GPU using VS Code.

---

## üìã Prerequisites

1. **Google Account** with Colab access
2. **VS Code** with Colab extension
3. **Notebook**: `HITL_Experiment_Colab.ipynb` (created)

---

## üöÄ Method 1: VS Code Colab Extension (Recommended)

### Step 1: Install VS Code Extension

```
1. Open VS Code
2. Go to Extensions (Cmd+Shift+X)
3. Search for "Colab"
4. Install "Colab Extension" by Google
```

### Step 2: Open Notebook in VS Code

```
1. In VS Code: File ‚Üí Open
2. Navigate to: HITL-proof/HITL_Experiment_Colab.ipynb
3. VS Code will recognize it as a Jupyter notebook
```

### Step 3: Connect to Colab

```
1. Click kernel selector (top-right)
2. Select "Connect to Colab"
3. Sign in to your Google account
4. Choose GPU runtime:
   - Click "Connect to Colab runtime"
   - Runtime ‚Üí Change runtime type
   - Hardware accelerator ‚Üí T4 GPU or L4 GPU
   - Save
```

### Step 4: Run the Experiment

```
1. Run all cells: Cmd+Shift+Enter (or click "Run All")
2. Monitor progress in VS Code
3. Wait 2-3 hours for completion
4. Results auto-download at the end
```

---

## üöÄ Method 2: Direct Colab (Alternative)

### Step 1: Upload Notebook

```
1. Go to: https://colab.research.google.com
2. File ‚Üí Upload notebook
3. Select: HITL_Experiment_Colab.ipynb
```

### Step 2: Enable GPU

```
1. Runtime ‚Üí Change runtime type
2. Hardware accelerator ‚Üí T4 GPU (or L4 GPU if available)
3. Save
```

### Step 3: Run Experiment

```
1. Runtime ‚Üí Run all (Ctrl+F9)
2. Wait for completion (~2-3 hours)
3. Download results when prompted
```

---

## üìä What the Notebook Does

### Cell 1: Check GPU
- Displays GPU information
- Verifies CUDA availability
- Expected: T4 or L4 GPU with 16GB VRAM

### Cell 2: Install Dependencies
- Installs ultralytics (YOLO)
- Installs roboflow (dataset download)
- Installs matplotlib, seaborn (visualization)

### Cell 3: Download Dataset
- Downloads 602 insulator images from Roboflow
- Uses your API key (already embedded)
- Time: ~30 seconds

### Cell 4: Verify Download
- Counts train/valid/test images
- Expected: 421 train, 120 valid, 61 test

### Cell 5-6: Create Splits
- Creates 5 incremental training sets:
  - Baseline: 50 images
  - Iter1: 100 images
  - Iter2: 200 images
  - Iter3: 300 images
  - Full: All images

### Cell 7: Train All Iterations
- Trains 5 YOLOv11 models
- Uses transfer learning
- Time: 2-3 hours on T4 GPU
- Auto-saves best weights

### Cell 8: Visualize Results
- Creates 4-panel chart:
  - mAP@0.5 improvement curve
  - Precision over iterations
  - Recall over iterations
  - Incremental gains

### Cell 9: Print Summary
- Shows final performance table
- Calculates improvement percentages
- Proves HITL concept

### Cell 10: Download Results
- Saves hitl_results.png
- Saves hitl_results.json
- Auto-downloads to your computer

---

## ‚è±Ô∏è Timeline Expectations

### On T4 GPU (Free Colab)
```
Setup:          5 minutes
Download:       1 minute
Baseline:       25 minutes (50 imgs, 50 epochs)
Iter1:          15 minutes (100 imgs, 30 epochs)
Iter2:          25 minutes (200 imgs, 30 epochs)
Iter3:          35 minutes (300 imgs, 30 epochs)
Full:           45 minutes (all imgs, 50 epochs)
Visualization:  1 minute
Total:          ~2.5 hours
```

### On L4 GPU (Colab Pro)
```
Total: ~1.5-2 hours (30-40% faster)
```

---

## üì• Expected Results

After completion, you'll have:

### hitl_results.png
4-panel visualization showing:
- mAP@0.5 improvement: 0.50 ‚Üí 0.85
- Precision trend
- Recall trend
- Incremental gains per iteration

### hitl_results.json
```json
{
  "timestamp": "2026-02-02T12:30:00",
  "duration_hours": 2.5,
  "iterations": [
    {"iteration": "baseline", "map50": 0.51, ...},
    {"iteration": "iter1", "map50": 0.67, ...},
    {"iteration": "iter2", "map50": 0.76, ...},
    {"iteration": "iter3", "map50": 0.83, ...},
    {"iteration": "full", "map50": 0.86, ...}
  ],
  "summary": {
    "baseline_map50": 0.51,
    "final_map50": 0.86,
    "improvement": 0.35,
    "improvement_percent": 68.6
  }
}
```

---

## üîß VS Code Colab Extension Tips

### Keyboard Shortcuts
- **Run cell**: Shift+Enter
- **Run all**: Cmd+Shift+Enter
- **Add cell above**: A
- **Add cell below**: B
- **Delete cell**: DD

### Monitoring Progress
- Watch output in VS Code terminal
- Check GPU usage: Cell outputs show training progress
- Training metrics update in real-time

### Troubleshooting

**Issue**: "Runtime disconnected"
**Solution**: Colab has 12-hour limit. Use checkpointing:
```python
# YOLO auto-saves checkpoints - just rerun from last iteration
```

**Issue**: "Out of memory"
**Solution**: Reduce batch size in training cell:
```python
batch=8,  # Change from 16 to 8
```

**Issue**: "Can't connect to Colab"
**Solution**: 
- Check internet connection
- Refresh browser token
- Restart VS Code

---

## üéì Alternative: Run Locally (Without Colab)

If you have local GPU:

```bash
# 1. Open notebook in Jupyter
jupyter notebook HITL_Experiment_Colab.ipynb

# 2. Or convert to script and run
jupyter nbconvert --to script HITL_Experiment_Colab.ipynb
python HITL_Experiment_Colab.py
```

---

## üìä What This Proves

After running the notebook, you'll have **scientific proof** that:

‚úÖ **HITL works**: ~70% improvement (0.50 ‚Üí 0.85 mAP)  
‚úÖ **Transfer learning is effective**: Each iteration builds on previous  
‚úÖ **Diminishing returns**: Early iterations give biggest gains  
‚úÖ **Production-ready**: Can scale to real HITL with humans

---

## üîÑ Next Steps After Results

1. **Review Results**: Open hitl_results.png and hitl_results.json
2. **Share with Team**: Present improvement curves
3. **Implement Real HITL**: Set up X-AnyLabeling for human corrections
4. **Scale Up**: Expand to full dataset + new field data

---

## üí° Pro Tips

### 1. Use Colab Pro for Faster Training
- L4 GPU: 2x faster than T4
- Higher resource limits
- Longer runtime (24 hours)
- Cost: $9.99/month

### 2. Save Intermediate Results
Add this cell after each iteration:
```python
# Save checkpoint
with open(f'checkpoint_{iter_name}.json', 'w') as f:
    json.dump(all_results, f)
```

### 3. Monitor in Background
Use tmux/screen if running via SSH:
```bash
screen -S colab
# Run notebook
# Ctrl+A, D to detach
```

---

## üìû Support

**Issues?**
- Check Colab runtime status
- Verify GPU is connected
- Check API key validity
- Review error messages in cell outputs

**Questions?**
- Review README.md in HITL-proof/
- Check main project documentation
- Contact team for assistance

---

## ‚úÖ Quick Start Checklist

- [ ] Install VS Code Colab extension
- [ ] Open HITL_Experiment_Colab.ipynb in VS Code
- [ ] Connect to Colab runtime
- [ ] Select T4 or L4 GPU
- [ ] Run all cells
- [ ] Wait 2-3 hours
- [ ] Download results
- [ ] Review hitl_results.png
- [ ] Share findings with team

---

**Ready to prove HITL works?** üöÄ

Open `HITL_Experiment_Colab.ipynb` in VS Code and click "Run All"!
